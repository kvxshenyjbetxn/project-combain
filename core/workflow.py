# core/workflow.py
import logging
import os
import threading
import concurrent.futures
import shutil
import numpy as np
import time
import re
from tkinter import messagebox

# –Ü–º–ø–æ—Ä—Ç—É—î–º–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ —É—Ç–∏–ª—ñ—Ç–∏ —Ç–∞ —Ñ—É–Ω–∫—Ü—ñ—ó
from utils.file_utils import sanitize_filename, chunk_text, chunk_text_voicemaker, chunk_text_speechify
from utils.media_utils import concatenate_audio_files, concatenate_videos

logger = logging.getLogger("TranslationApp")

class WorkflowManager:
    def __init__(self, app_instance):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î –º–µ–Ω–µ–¥–∂–µ—Ä —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤.
        'app_instance' - —Ü–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –≥–æ–ª–æ–≤–Ω–∏–π –∫–ª–∞—Å TranslationApp –¥–ª—è –¥–æ—Å—Ç—É–ø—É –¥–æ –π–æ–≥–æ —Å—Ç–∞–Ω—É —Ç–∞ API.
        """
        self.app = app_instance
        self.config = app_instance.config
        # –û—Ç—Ä–∏–º—É—î–º–æ –¥–æ—Å—Ç—É–ø –¥–æ –≤—Å—ñ—Ö API —á–µ—Ä–µ–∑ –≥–æ–ª–æ–≤–Ω–∏–π –∫–ª–∞—Å
        self.or_api = app_instance.or_api
        self.poll_api = app_instance.poll_api
        self.recraft_api = app_instance.recraft_api
        self.el_api = app_instance.el_api
        self.vm_api = app_instance.vm_api
        self.speechify_api = app_instance.speechify_api
        self.montage_api = app_instance.montage_api
        self.tg_api = app_instance.tg_api
        self.firebase_api = app_instance.firebase_api

    # –¢—É—Ç –±—É–¥—É—Ç—å –∑–Ω–∞—Ö–æ–¥–∏—Ç–∏—Å—å –º–µ—Ç–æ–¥–∏ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –∑–∞–≤–¥–∞–Ω—å

    def _process_hybrid_queue(self, queue_to_process_list, queue_type):
        is_rewrite = queue_type == 'rewrite'
        if is_rewrite:
            self.app.is_processing_rewrite_queue = True
        else:
            self.app.is_processing_queue = True
        
        # Setup Firebase command listening and clear old data if enabled
        if self.firebase_api.is_initialized:
            self.app.stop_command_listener.clear()
            # Clear previous commands and images before starting new session
            self.firebase_api.clear_commands()
            self.firebase_api.clear_montage_ready_status()  # Clear montage ready status
            
            if self.config.get("firebase", {}).get("auto_clear_gallery", True):
                self.firebase_api.clear_images()  # Clear old gallery images
                logger.info("Auto-cleared old gallery images from Firebase for new generation session")
            
            self.app.command_listener_thread = threading.Thread(target=self.app._command_listener_worker, daemon=True)
            self.app.command_listener_thread.start()
            # Start queue processor
            self.app.root.after(100, self.app._process_command_queue)

        self.app._update_button_states(is_processing=True, is_image_stuck=False)

        try:
            queue_to_process = list(queue_to_process_list)
            if is_rewrite:
                self.app.rewrite_task_queue.clear()
                self.app.update_rewrite_queue_display()
            else:
                self.app.task_queue.clear()
                self.app.update_queue_display()
            
            # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å—Ç–∞—Ç—É—Å—É –¥–ª—è –≤—Å—ñ—Ö –∑–∞–≤–¥–∞–Ω—å —É —á–µ—Ä–∑—ñ
            self.app.task_completion_status = {}
            for i, task in enumerate(queue_to_process):
                task['task_index'] = i
                for lang_code in task['selected_langs']:
                    task_key = f"{i}_{lang_code}"
                    self.app.task_completion_status[task_key] = {
                        "task_name": task.get('task_name'),
                        "steps": {self.app._t('step_name_' + step_name): "‚ö™Ô∏è" for step_name, enabled in task['steps'][lang_code].items() if enabled},
                        "images_generated": 0, # –õ—ñ—á–∏–ª—å–Ω–∏–∫ —É—Å–ø—ñ—à–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å
                        "total_images": 0      # –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
                    }

            processing_data = {}

            # Phase 0: Transcription (only for rewrite mode)
            if is_rewrite:
                self.app.update_progress(self.app._t('phase_0_transcription'))
                logger.info("Hybrid mode -> Phase 0: Sequential transcription of local files.")
                
                transcribed_texts = {}
                rewrite_base_dir = self.config['output_settings']['rewrite_default_dir']
                
                for task in queue_to_process:
                    mp3_path = task['mp3_path']
                    original_filename = task['original_filename']
                    
                    if mp3_path not in transcribed_texts:
                        # Clean filename and sanitize for directory creation
                        video_title = sanitize_filename(os.path.splitext(original_filename)[0])
                        task_output_dir = os.path.join(rewrite_base_dir, video_title)
                        os.makedirs(task_output_dir, exist_ok=True)
                        original_transcript_path = os.path.join(task_output_dir, "original_transcript.txt")
                        
                        if os.path.exists(original_transcript_path):
                            with open(original_transcript_path, "r", encoding='utf-8') as f:
                                transcribed_text = f.read()
                        else:
                            model = self.montage_api._load_whisper_model()
                            if not model:
                                logger.error("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å Whisper. –ü–µ—Ä–µ—Ä–∏–≤–∞–Ω–Ω—è.")
                                return
                            transcription_result = model.transcribe(mp3_path, verbose=False)
                            transcribed_text = transcription_result['text']
                            with open(original_transcript_path, "w", encoding='utf-8') as f:
                                f.write(transcribed_text)

                        transcribed_texts[mp3_path] = {"text": transcribed_text, "title": video_title}

                for task in queue_to_process:
                    if task['mp3_path'] in transcribed_texts:
                        task['transcribed_text'] = transcribed_texts[task['mp3_path']]['text']
                        task['video_title'] = transcribed_texts[task['mp3_path']]['title']
                        
                        # –û–Ω–æ–≤–ª—é—î–º–æ —Å—Ç–∞—Ç—É—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –¥–ª—è –≤—Å—ñ—Ö –º–æ–≤ —É —Ü—å–æ–º—É –∑–∞–≤–¥–∞–Ω–Ω—ñ
                        task_idx_str = task['task_index']
                        step_name_key = self.app._t('step_name_transcribe')
                        for lang_code in task['selected_langs']:
                            status_key = f"{task_idx_str}_{lang_code}"
                            if status_key in self.app.task_completion_status and step_name_key in self.app.task_completion_status[status_key]['steps']:
                                self.app.task_completion_status[status_key]['steps'][step_name_key] = "‚úÖ"


            # Phase 1: Parallel text processing
            self.app.update_progress(self.app._t('phase_1_text_processing'))
            logger.info(f"Hybrid mode -> Phase 1: Parallel text processing for {len(queue_to_process)} tasks.")
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
                text_futures = {}
                worker = self._rewrite_text_processing_worker if is_rewrite else self._text_processing_worker

                for task_index, task in enumerate(queue_to_process):
                    if is_rewrite and 'transcribed_text' not in task:
                        continue
                    
                    for lang_code in task['selected_langs']:
                        task_key = (task_index, lang_code)
                        processing_data[task_key] = {'task': task} 
                        future = executor.submit(worker, task, lang_code)
                        text_futures[future] = task_key
                
                for future in concurrent.futures.as_completed(text_futures):
                    task_key = text_futures[future]
                    processing_data[task_key]['text_results'] = future.result()

            logger.info("–ì—ñ–±—Ä–∏–¥–Ω–∏–π —Ä–µ–∂–∏–º -> –ï—Ç–∞–ø 1: –û–±—Ä–æ–±–∫—É —Ç–µ–∫—Å—Ç—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
            
            # --- –û–ù–û–í–õ–ï–ù–ò–ô –ë–õ–û–ö –ü–Ü–°–õ–Ø –û–ë–†–û–ë–ö–ò –¢–ï–ö–°–¢–£ ---
            for task_key, data in processing_data.items():
                task_idx_str, lang_code = task_key
                status_key = f"{task_idx_str}_{lang_code}"

                if status_key in self.app.task_completion_status:
                    if data.get('text_results'):
                        # –í—ñ–¥–º—ñ—á–∞—î–º–æ —É—Å–ø—ñ—à–Ω—ñ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –µ—Ç–∞–ø—ñ–≤
                        steps_to_mark = ['translate', 'rewrite', 'cta', 'gen_prompts']
                        for step in steps_to_mark:
                            step_name_key = self.app._t('step_name_' + step)
                            if step_name_key in self.app.task_completion_status[status_key]['steps']:
                                self.app.task_completion_status[status_key]['steps'][step_name_key] = "‚úÖ"
                        
                        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–ª–∞–Ω–æ–≤–∞–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å
                        num_prompts = len(data['text_results'].get("prompts", []))
                        self.app.task_completion_status[status_key]["total_images"] = num_prompts
                    else:
                        # –Ø–∫—â–æ —Ç–µ–∫—Å—Ç–æ–≤–∏–π –µ—Ç–∞–ø –ø—Ä–æ–≤–∞–ª–∏–≤—Å—è, –≤—ñ–¥–º—ñ—á–∞—î–º–æ –≤—Å—ñ –Ω–∞—Å—Ç—É–ø–Ω—ñ —è–∫ –ø—Ä–æ–≤–∞–ª–µ–Ω—ñ
                        for step_name in self.app.task_completion_status[status_key]['steps']:
                            self.app.task_completion_status[status_key]['steps'][step_name] = "‚ùå"


            # --- –ï–¢–ê–ü 2: –û–î–ù–û–ß–ê–°–ù–ê –ì–ï–ù–ï–†–ê–¶–Ü–Ø –ú–ï–î–Ü–ê ---
            self.app.update_progress(self.app._t('phase_2_media_generation'))
            logger.info("–ì—ñ–±—Ä–∏–¥–Ω–∏–π —Ä–µ–∂–∏–º -> –ï—Ç–∞–ø 2: –û–¥–Ω–æ—á–∞—Å–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –º–µ–¥—ñ–∞.")
            
            self.app.root.after(0, self.app.setup_empty_gallery, queue_type, queue_to_process)
            
            should_gen_images = any(
                data.get('text_results') and data['task']['steps'][key[1]].get('gen_images')
                for key, data in processing_data.items()
            )

            if should_gen_images:
                image_master_thread = threading.Thread(target=self._sequential_image_master, args=(processing_data, queue_to_process))
                image_master_thread.start()
            else:
                image_master_thread = None
                logger.info("Hybrid mode -> Image generation disabled for all tasks. Skipping.")

            audio_subs_master_thread = threading.Thread(target=self._audio_subs_pipeline_master, args=(processing_data,))
            audio_subs_master_thread.start()
            
            if image_master_thread:
                image_master_thread.join()
            audio_subs_master_thread.join()
            
            logger.info("–ì—ñ–±—Ä–∏–¥–Ω–∏–π —Ä–µ–∂–∏–º -> –ï—Ç–∞–ø 2: –ì–µ–Ω–µ—Ä–∞—Ü—ñ—é –≤—Å—ñ—Ö –º–µ–¥—ñ–∞—Ñ–∞–π–ª—ñ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
            
            # --- –ï–¢–ê–ü 3: –û–ü–¶–Ü–û–ù–ê–õ–¨–ù–ê –ü–ê–£–ó–ê ---
            if self.config.get("ui_settings", {}).get("image_control_enabled", False) and should_gen_images:
                self.app.update_progress(self.app._t('phase_3_image_control'))
                logger.info("–ì—ñ–±—Ä–∏–¥–Ω–∏–π —Ä–µ–∂–∏–º -> –ï—Ç–∞–ø 3: –ü–∞—É–∑–∞ –¥–ª—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º.")
                
                # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ —Å—Ç–∞—Ç—É—Å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—ñ –¥–æ –º–æ–Ω—Ç–∞–∂—É –≤ Firebase
                self.firebase_api.send_montage_ready_status()
                
                # –ù–∞–¥—Å–∏–ª–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ Telegram
                self.tg_api.send_message_with_buttons(
                    message="üé® *–ö–æ–Ω—Ç—Ä–æ–ª—å –∑–æ–±—Ä–∞–∂–µ–Ω—å*\n\n–í—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ\\. –ë—É–¥—å –ª–∞—Å–∫–∞, –ø–µ—Ä–µ–≥–ª—è–Ω—å—Ç–µ —Ç–∞ –≤—ñ–¥—Ä–µ–¥–∞–≥—É–π—Ç–µ —ó—Ö —É –ø—Ä–æ–≥—Ä–∞–º—ñ, –ø–µ—Ä—à –Ω—ñ–∂ –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –º–æ–Ω—Ç–∞–∂\\.",
                    buttons=[
                        {"text": "‚úÖ –ü—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –º–æ–Ω—Ç–∞–∂", "callback_data": "continue_montage_action"}
                    ]
                )

                self.app.image_control_active.wait()
            else:
                logger.info("–ì—ñ–±—Ä–∏–¥–Ω–∏–π —Ä–µ–∂–∏–º -> –ï—Ç–∞–ø 3: –ü–∞—É–∑–∞ –≤–∏–º–∫–Ω–µ–Ω–∞ –∞–±–æ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–∞, –ø–µ—Ä–µ—Ö—ñ–¥ –¥–æ –º–æ–Ω—Ç–∞–∂—É.")

            # Phase 4: Final montage and language reports
            self.app.update_progress(self.app._t('phase_4_final_montage'))
            logger.info("Hybrid mode -> Phase 4: Starting final montage and language reports.")

            for task_key, data in sorted(processing_data.items()):
                lang_code = task_key[1]
                task_idx_str = task_key[0]
                status_key = f"{task_idx_str}_{lang_code}"
                
                if data.get('task') and data.get('text_results') and data['task']['steps'][lang_code].get('create_video'):
                    
                    images_folder = data['text_results']['images_folder']
                    all_images = sorted([os.path.join(images_folder, f) for f in os.listdir(images_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
                    
                    if not data.get('audio_chunks') or not data.get('subs_chunks'):
                        logger.error(f"Audio or subtitles missing for task {task_key}. Skipping video montage.")
                        if status_key in self.app.task_completion_status:
                            step_name = self.app._t('step_name_create_video')
                            self.app.task_completion_status[status_key]['steps'][step_name] = "‚ùå"
                        continue
                        
                    if not all_images:
                        logger.error(f"–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–ª—è –∑–∞–≤–¥–∞–Ω–Ω—è {task_key}. –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –º–æ–Ω—Ç–∞–∂ –≤—ñ–¥–µ–æ.")
                        if status_key in self.app.task_completion_status:
                            step_name = self.app._t('step_name_create_video')
                            self.app.task_completion_status[status_key]['steps'][step_name] = "‚ùå"
                        continue

                    image_chunks = np.array_split(all_images, len(data['audio_chunks']))
                    
                    video_chunk_paths = []
                    num_montage_threads = self.config.get('parallel_processing', {}).get('num_chunks', 3)

                    with concurrent.futures.ThreadPoolExecutor(max_workers=num_montage_threads) as executor:
                        video_futures = {
                            executor.submit(
                                self._video_chunk_worker, 
                                self.app,
                                list(image_chunks[i]), 
                                data['audio_chunks'][i], 
                                data['subs_chunks'][i],
                                os.path.join(data['temp_dir'], f"video_chunk_{i}.mp4"),
                                i + 1, len(data['audio_chunks'])
                            ): i for i in range(len(data['audio_chunks']))
                        }
                        for f in concurrent.futures.as_completed(video_futures):
                            result = f.result()
                            if result: video_chunk_paths.append(result)

                    if len(video_chunk_paths) == len(data['audio_chunks']):
                        if 'video_title' in data['text_results']:
                            base_name = sanitize_filename(data['text_results']['video_title'])
                        else:
                            base_name = sanitize_filename(data['text_results'].get('task_name', f"Task_{task_key[0]}"))
                        
                        final_video_path = os.path.join(data['text_results']['output_path'], f"video_{base_name}_{lang_code}.mp4")
                        if self._concatenate_videos(self.app, sorted(video_chunk_paths), final_video_path):
                            logger.info(f"–£–°–ü–Ü–•: –°—Ç–≤–æ—Ä–µ–Ω–æ —Ñ—ñ–Ω–∞–ª—å–Ω–µ –≤—ñ–¥–µ–æ: {final_video_path}")
                            if status_key in self.app.task_completion_status:
                                step_name = self.app._t('step_name_create_video')
                                self.app.task_completion_status[status_key]['steps'][step_name] = "‚úÖ"
                            if is_rewrite:
                                self.app.save_processed_link(data['task']['original_filename'])
                        else:
                             if status_key in self.app.task_completion_status:
                                step_name = self.app._t('step_name_create_video')
                                self.app.task_completion_status[status_key]['steps'][step_name] = "‚ùå"
                    else:
                        logger.error(f"–ü–û–ú–ò–õ–ö–ê: –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –≤—Å—ñ —á–∞—Å—Ç–∏–Ω–∏ –≤—ñ–¥–µ–æ –¥–ª—è –∑–∞–≤–¥–∞–Ω–Ω—è {task_key}.")
                        if status_key in self.app.task_completion_status:
                            step_name = self.app._t('step_name_create_video')
                            self.app.task_completion_status[status_key]['steps'][step_name] = "‚ùå"
                
                # –í—ñ–¥–ø—Ä–∞–≤–∫–∞ –∑–≤—ñ—Ç—É –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –æ–±—Ä–æ–±–∫–∏ –æ–¥–Ω—ñ—î—ó –º–æ–≤–∏
                report_timing = self.config.get("telegram", {}).get("report_timing", "per_task")
                if report_timing == "per_language":
                    self.app.send_task_completion_report(data['task'], single_lang_code=lang_code)

            # --- –§–Ü–ù–ê–õ–¨–ù–ò–ô –ö–†–û–ö: –í–Ü–î–ü–†–ê–í–ö–ê –ó–í–Ü–¢–Ü–í –î–õ–Ø –í–°–¨–û–ì–û –ó–ê–í–î–ê–ù–ù–Ø ---
            logger.info("–ì—ñ–±—Ä–∏–¥–Ω–∏–π —Ä–µ–∂–∏–º -> –í—Å—ñ –∑–∞–≤–¥–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í—ñ–¥–ø—Ä–∞–≤–∫–∞ —Ñ—ñ–Ω–∞–ª—å–Ω–∏—Ö –∑–≤—ñ—Ç—ñ–≤...")
            report_timing = self.config.get("telegram", {}).get("report_timing", "per_task")
            if report_timing == "per_task":
                for task_config in queue_to_process:
                    self.app.send_task_completion_report(task_config)
            
            self.app.root.after(0, lambda: self.app.progress_label.config(text=self.app._t('status_complete')))
            self.app.root.after(0, lambda: messagebox.showinfo(self.app._t('queue_title'), self.app._t('info_queue_complete')))

        except Exception as e:
            logger.exception(f"CRITICAL ERROR: Unexpected error in hybrid queue processing: {e}")
        finally:
            # Cleanup temporary files
            keep_temp_files = self.config.get('parallel_processing', {}).get('keep_temp_files', False)
            if not keep_temp_files:
                self.app.update_progress(self.app._t('phase_cleaning_up'))
                for task_key, data in processing_data.items():
                    if 'temp_dir' in data and os.path.exists(data['temp_dir']):
                        try:
                            shutil.rmtree(data['temp_dir'])
                            logger.info(f"Cleaned temporary directory: {data['temp_dir']}")
                        except Exception as e:
                            logger.error(f"Failed to delete temporary directory {data['temp_dir']}: {e}")

            self.app.stop_telegram_polling.set()
            self.app._update_button_states(is_processing=False, is_image_stuck=False)
            if is_rewrite:
                self.app.is_processing_rewrite_queue = False
                self.app.root.after(0, self.app.update_rewrite_queue_display)
            else:
                self.app.is_processing_queue = False
                self.app.root.after(0, self.app.update_queue_display)
            
            if hasattr(self.app, 'pause_resume_button'):
                 self.app.root.after(0, lambda: self.app.pause_resume_button.config(text=self.app._t('pause_button'), state="disabled"))
            self.app.pause_event.set()

    def _text_processing_worker(self, task, lang_code):
        """Execute all text operations for a single language task."""
        try:
            lang_name = lang_code.upper()
            lang_config = self.config["languages"][lang_code]
            lang_steps = task['steps'][lang_code]
            output_cfg = self.config.get("output_settings", {})
            use_default_dir = output_cfg.get("use_default_dir", False)

            # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—É –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
            if use_default_dir:
                task_name = sanitize_filename(task.get('task_name', f"Task_{int(time.time())}"))
                output_path = os.path.join(output_cfg.get("default_dir", ""), task_name, lang_name)
            else:
                output_path = task['lang_output_paths'].get(lang_code)
            
            if not output_path:
                logger.error(f"–ù–µ–º–∞—î —à–ª—è—Ö—É –≤–∏–≤–æ–¥—É –¥–ª—è {lang_name} —É –∑–∞–≤–¥–∞–Ω–Ω—ñ {task.get('task_name')}.")
                return None
            os.makedirs(output_path, exist_ok=True)

            text_to_process = task['input_text']
            translation_path = os.path.join(output_path, "translation.txt")

            # Translation logic
            if lang_steps.get('translate'):
                translated_text = self.or_api.translate_text(
                    task['input_text'], self.config["openrouter"]["translation_model"],
                    self.config["openrouter"]["translation_params"], lang_name,
                    custom_prompt_template=lang_config.get("prompt")
                )
                if translated_text:
                    text_to_process = translated_text
                    with open(translation_path, 'w', encoding='utf-8') as f:
                        f.write(translated_text)
                else:
                    logger.error(f"Translation failed for {lang_name}.")
                    return None
            elif os.path.exists(translation_path):
                 with open(translation_path, 'r', encoding='utf-8') as f:
                    text_to_process = f.read()
                 logger.info(f"Using existing translation file for {lang_name}: {translation_path}")
            else:
                logger.info(f"Translation step is disabled and no existing translation file was found for {lang_name}. Using original text.")
                text_to_process = task['input_text']

            cta_text, raw_prompts = None, None
            prompts_path = os.path.join(output_path, "image_prompts.txt")
            
            # Generate CTA (always from text_to_process)
            if lang_steps.get('cta'):
                 cta_text = self.or_api.generate_call_to_action(text_to_process, self.config["openrouter"]["cta_model"], self.config["openrouter"]["cta_params"], lang_name)
                 if cta_text:
                     with open(os.path.join(output_path, "call_to_action.txt"), 'w', encoding='utf-8') as f: f.write(cta_text)

            # Generate or read prompts
            image_prompts = []
            if lang_steps.get('gen_prompts'):
                raw_prompts = self.or_api.generate_image_prompts(text_to_process, self.config["openrouter"]["prompt_model"], self.config["openrouter"]["prompt_params"], lang_name)
                if raw_prompts:
                    with open(prompts_path, 'w', encoding='utf-8') as f: f.write(raw_prompts)
            elif os.path.exists(prompts_path):
                logger.info(f"Using existing prompts file: {prompts_path}")
                with open(prompts_path, 'r', encoding='utf-8') as f:
                    raw_prompts = f.read()

            if raw_prompts:
                # –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ –ª–æ–≥—ñ–∫–∞: –æ–±'—î–¥–Ω—É—î–º–æ –±–∞–≥–∞—Ç–æ—Ä—è–¥–∫–æ–≤—ñ –ø—Ä–æ–º–ø—Ç–∏, –∞ –ø–æ—Ç—ñ–º —Ä–æ–∑–¥—ñ–ª—è—î–º–æ –∑–∞ –Ω—É–º–µ—Ä–∞—Ü—ñ—î—é
                # –°–ø–æ—á–∞—Ç–∫—É –∑–∞–º—ñ–Ω—é—î–º–æ –≤—Å—ñ –ø–µ—Ä–µ–Ω–æ—Å–∏ —Ä—è–¥–∫—ñ–≤ –Ω–∞ –ø—Ä–æ–±—ñ–ª–∏
                single_line_text = raw_prompts.replace('\n', ' ').strip()
                # –†–æ–∑–¥—ñ–ª—è—î–º–æ –∑–∞ —à–∞–±–ª–æ–Ω–æ–º "—á–∏—Å–ª–æ." (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1.", "2." —ñ —Ç.–¥.), –≤–∏–¥–∞–ª—è—é—á–∏ —Å–∞–º —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫
                prompt_blocks = re.split(r'\s*\d+[\.\)]\s*', single_line_text)
                # –ü–µ—Ä—à–∏–π –µ–ª–µ–º–µ–Ω—Ç –ø—ñ—Å–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –∑–∞–∑–≤–∏—á–∞–π –ø–æ—Ä–æ–∂–Ω—ñ–π, —Ç–æ–º—É –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤—É—î–º–æ –π–æ–≥–æ
                image_prompts = [block.strip() for block in prompt_blocks if block.strip()]

            images_folder = os.path.join(output_path, "images")
            os.makedirs(images_folder, exist_ok=True)

            return {
                "text_to_process": text_to_process,
                "output_path": output_path,
                "prompts": image_prompts,
                "images_folder": images_folder,
                "task_name": task.get('task_name', 'Untitled_Task')
            }
        except Exception as e:
            logger.exception(f"Error in text processing worker for {lang_code}: {e}")
            return None

    def _rewrite_text_processing_worker(self, task, lang_code):
        """–û–±—Ä–æ–±–ª—è—î –í–ñ–ï —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–æ–≤–∞–Ω–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–≤–¥–∞–Ω–Ω—è —Ä–µ—Ä–∞–π—Ç—É."""
        try:
            video_title = task['video_title']
            transcribed_text = task['transcribed_text']
            rewrite_base_dir = self.config['output_settings']['rewrite_default_dir']

            if not transcribed_text.strip(): return None

            # –ü–æ–¥–∞–ª—å—à–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó –º–æ–≤–∏
            lang_output_path = os.path.join(rewrite_base_dir, video_title, lang_code.upper())
            os.makedirs(lang_output_path, exist_ok=True)

            selected_template_name = self.app.rewrite_template_var.get()
            rewrite_prompt_template = self.config.get("rewrite_prompt_templates", {}).get(selected_template_name, {}).get(lang_code)
            
            rewritten_text = self.or_api.rewrite_text(transcribed_text, self.config["openrouter"]["rewrite_model"], self.config["openrouter"]["rewrite_params"], rewrite_prompt_template)
            if not rewritten_text: return None
            
            with open(os.path.join(lang_output_path, "rewritten_text.txt"), "w", encoding='utf-8') as f: f.write(rewritten_text)
            
            # CTA —Ç–∞ –ø—Ä–æ–º—Ç–∏
            cta_path = os.path.join(lang_output_path, "call_to_action.txt")
            prompts_path = os.path.join(lang_output_path, "image_prompts.txt")

            # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è CTA –∞–±–æ —á–∏—Ç–∞–Ω–Ω—è –∑ —Ñ–∞–π–ª—É
            if task['steps'][lang_code]['cta']:
                cta_text = self.or_api.generate_call_to_action(rewritten_text, self.config["openrouter"]["cta_model"], self.config["openrouter"]["cta_params"])
                if cta_text:
                    with open(cta_path, 'w', encoding='utf-8') as f: f.write(cta_text)

            # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—Ä–æ–º—Ç—ñ–≤ –∞–±–æ —á–∏—Ç–∞–Ω–Ω—è –∑ —Ñ–∞–π–ª—É
            raw_prompts = None
            if task['steps'][lang_code]['gen_prompts']:
                raw_prompts = self.or_api.generate_image_prompts(rewritten_text, self.config["openrouter"]["prompt_model"], self.config["openrouter"]["prompt_params"])
                if raw_prompts:
                    with open(prompts_path, 'w', encoding='utf-8') as f: f.write(raw_prompts)
            elif os.path.exists(prompts_path):
                logger.info(f"Using existing prompts file for rewrite task: {prompts_path}")
                with open(prompts_path, 'r', encoding='utf-8') as f:
                    raw_prompts = f.read()

            image_prompts = []
            if raw_prompts:
                # –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ –ª–æ–≥—ñ–∫–∞: –æ–±'—î–¥–Ω—É—î–º–æ –±–∞–≥–∞—Ç–æ—Ä—è–¥–∫–æ–≤—ñ –ø—Ä–æ–º–ø—Ç–∏, –∞ –ø–æ—Ç—ñ–º —Ä–æ–∑–¥—ñ–ª—è—î–º–æ –∑–∞ –Ω—É–º–µ—Ä–∞—Ü—ñ—î—é
                # –°–ø–æ—á–∞—Ç–∫—É –∑–∞–º—ñ–Ω—é—î–º–æ –≤—Å—ñ –ø–µ—Ä–µ–Ω–æ—Å–∏ —Ä—è–¥–∫—ñ–≤ –Ω–∞ –ø—Ä–æ–±—ñ–ª–∏
                single_line_text = raw_prompts.replace('\n', ' ').strip()
                # –†–æ–∑–¥—ñ–ª—è—î–º–æ –∑–∞ —à–∞–±–ª–æ–Ω–æ–º "—á–∏—Å–ª–æ." (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1.", "2." —ñ —Ç.–¥.), –≤–∏–¥–∞–ª—è—é—á–∏ —Å–∞–º —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫
                prompt_blocks = re.split(r'\s*\d+[\.\)]\s*', single_line_text)
                # –ü–µ—Ä—à–∏–π –µ–ª–µ–º–µ–Ω—Ç –ø—ñ—Å–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –∑–∞–∑–≤–∏—á–∞–π –ø–æ—Ä–æ–∂–Ω—ñ–π, —Ç–æ–º—É –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤—É—î–º–æ –π–æ–≥–æ
                image_prompts = [block.strip() for block in prompt_blocks if block.strip()]

            images_folder = os.path.join(lang_output_path, "images")
            os.makedirs(images_folder, exist_ok=True)
            
            return {
                "text_to_process": rewritten_text, "output_path": lang_output_path,
                "prompts": image_prompts, "images_folder": images_folder, "video_title": video_title
            }
        except Exception as e:
            logger.exception(f"Error in rewrite text processing worker for {lang_code}: {e}")
            return None

    def _sequential_image_master(self, processing_data, queue_to_process):
        """–ì–æ–ª–æ–≤–Ω–∏–π –ø–æ—Ç—ñ–∫, —â–æ –∫–µ—Ä—É—î –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—é –≥–µ–Ω–µ—Ä–∞—Ü—ñ—î—é –≤—Å—ñ—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å."""
        logger.info("[Image Control] Image Master Thread: Starting sequential image generation.")
        for task_key, data in sorted(processing_data.items()):
            task_idx_str, lang_code = task_key
            status_key = f"{task_idx_str}_{lang_code}"
            step_name = self.app._t('step_name_gen_images')

            if data.get('text_results') and data['task']['steps'][lang_code].get('gen_images'):
                success = self._image_generation_worker(data, task_key, task_idx_str + 1, len(queue_to_process))
                if status_key in self.app.task_completion_status:
                    # –¢–µ–ø–µ—Ä –º–∏ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –±—É–ª–∏ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω—ñ —è–∫—ñ—Å—å –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                    if self.app.task_completion_status[status_key]["images_generated"] > 0:
                        self.app.task_completion_status[status_key]['steps'][step_name] = "‚úÖ"
                    else:
                        # –Ø–∫—â–æ –∂–æ–¥–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ, –≤–≤–∞–∂–∞—î–º–æ –∫—Ä–æ–∫ –ø—Ä–æ–≤–∞–ª–µ–Ω–∏–º
                        self.app.task_completion_status[status_key]['steps'][step_name] = "‚ùå"
            else:
                if status_key in self.app.task_completion_status and step_name in self.app.task_completion_status[status_key]['steps']:
                    self.app.task_completion_status[status_key]['steps'][step_name] = "‚ö™Ô∏è" # Mark as skipped, not failed

        logger.info("[Image Control] Image Master Thread: All image generation tasks complete.")

    def _image_generation_worker(self, data, task_key, task_num, total_tasks):
        prompts = data['text_results']['prompts']
        images_folder = data['text_results']['images_folder']
        lang_name = task_key[1].upper()

        with self.app.image_api_lock:
            if self.app.active_image_api is None:
                self.app.active_image_api = self.app.active_image_api_var.get()

        logger.info(f"Starting generation of {len(prompts)} images for {lang_name} using {self.app.active_image_api.capitalize()}.")

        auto_switch_enabled = self.config.get("ui_settings", {}).get("auto_switch_service_on_fail", False)
        retry_limit_for_switch = self.config.get("ui_settings", {}).get("auto_switch_retry_limit", 10)
        
        consecutive_failures = 0
        all_successful = True

        i = 0
        while i < len(prompts):
            if not self.app._check_app_state():
                all_successful = False
                break

            prompt = prompts[i]
            with self.app.image_api_lock:
                current_api_for_generation = self.app.active_image_api

            progress_text = f"–ó–∞–≤–¥.{task_num}/{total_tasks} | {lang_name} - [{current_api_for_generation.capitalize()}] {self.app._t('step_gen_images')} {i+1}/{len(prompts)}..."
            self.app.update_progress(progress_text)

            image_path = os.path.join(images_folder, f"image_{i+1:03d}.jpg")

            # Check for user interruption events
            if self.app.skip_image_event.is_set():
                self.app.skip_image_event.clear()
                logger.warning(f"Skipping image {i+1} by user command.")
                i += 1
                continue

            if self.app.regenerate_alt_service_event.is_set():
                self.app.regenerate_alt_service_event.clear()
                logger.warning(f"Attempting to regenerate image {i+1} with alternate service.")
                with self.app.image_api_lock:
                    alt_service = "recraft" if self.app.active_image_api == "pollinations" else "pollinations"
                
                success_alt = False
                if alt_service == "pollinations":
                    success_alt = self.poll_api.generate_image(prompt, image_path)
                elif alt_service == "recraft":
                    success_alt, _ = self.recraft_api.generate_image(prompt, image_path)

                if success_alt:
                    logger.info(f"[{alt_service.capitalize()}] Successfully regenerated image {i+1} with alternate service.")
                    # –õ–æ–≥—ñ–∫–∞ —É—Å–ø—ñ—à–Ω–æ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó, —è–∫ —É –∑–≤–∏—á–∞–π–Ω–æ–º—É –≤–∏–ø–∞–¥–∫—É
                    consecutive_failures = 0
                    self.app.image_prompts_map[image_path] = prompt
                    self.app.root.after(0, self.app._add_image_to_gallery, image_path, task_key)
                    status_key = f"{task_key[0]}_{task_key[1]}"
                    if status_key in self.app.task_completion_status:
                        self.app.task_completion_status[status_key]["images_generated"] += 1
                else:
                    logger.error(f"Alternate service [{alt_service.capitalize()}] also failed to generate image {i+1}.")
                    all_successful = False
                
                i += 1
                continue
            
            # Standard image generation process
            success = False
            if current_api_for_generation == "pollinations":
                success = self.poll_api.generate_image(prompt, image_path)
            elif current_api_for_generation == "recraft":
                success, _ = self.recraft_api.generate_image(prompt, image_path)

            if success:
                consecutive_failures = 0 
                logger.info(f"[{current_api_for_generation.capitalize()}] Successfully generated image {i+1}/{len(prompts)}.")
                self.app.image_prompts_map[image_path] = prompt
                
                # Add image to local gallery and Firebase
                self.app.root.after(0, self.app._add_image_to_gallery, image_path, task_key)
                if self.firebase_api.is_initialized:
                    task_name = data['task'].get('task_name', f"Task {task_key[0]}")
                    
                    # Callback –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–∞–ø—É–≤–∞–Ω–Ω—è –ø—ñ—Å–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
                    def save_mapping(image_id, local_path):
                        self.app.image_id_to_path_map[image_id] = local_path
                        logger.info(f"–ó–±–µ—Ä–µ–∂–µ–Ω–æ –º–∞–ø—É–≤–∞–Ω–Ω—è: {image_id} -> {os.path.basename(local_path)}")
                    
                    self.firebase_api.upload_and_add_image_in_thread(image_path, task_key, i, task_name, prompt, callback=save_mapping)

                status_key = f"{task_key[0]}_{task_key[1]}"
                if status_key in self.app.task_completion_status:
                    self.app.task_completion_status[status_key]["images_generated"] += 1
                i += 1 
            else:
                consecutive_failures += 1
                logger.error(f"[{current_api_for_generation.capitalize()}] Failed to generate image {i+1}. Consecutive failures: {consecutive_failures}.")
                
                # –õ–æ–≥—ñ–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ –ø–µ—Ä–µ–º–∏–∫–∞–Ω–Ω—è
                if auto_switch_enabled and consecutive_failures >= retry_limit_for_switch:
                    logger.warning(f"Reached {consecutive_failures} consecutive failures. Triggering automatic service switch.")
                    with self.app.image_api_lock:
                        new_service = "recraft" if self.app.active_image_api == "pollinations" else "pollinations"
                        self.app.active_image_api = new_service
                        self.app.active_image_api_var.set(new_service) # –û–Ω–æ–≤–ª—é—î–º–æ –∑–º—ñ–Ω–Ω—É –¥–ª—è GUI
                        logger.warning(f"Service automatically switched to: {self.app.active_image_api.capitalize()}")
                    consecutive_failures = 0
                    continue 

                # –õ–æ–≥—ñ–∫–∞ —Ä—É—á–Ω–æ–≥–æ –≤—Ç—Ä—É—á–∞–Ω–Ω—è
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ª—ñ–º—ñ—Ç –∑ Pollinations —è–∫ —Ç—Ä–∏–≥–µ—Ä –¥–ª—è –∫–Ω–æ–ø–æ–∫
                manual_intervention_limit = self.config.get("pollinations", {}).get("retries", 5)
                if consecutive_failures >= manual_intervention_limit:
                    logger.error(f"{manual_intervention_limit} consecutive failures for one image. Activating manual controls.")
                    self.app._update_button_states(is_processing=True, is_image_stuck=True)
                    self.tg_api.send_message_with_buttons(
                        message="‚ùå *–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è*\n\n–ù–µ –≤–¥–∞—î—Ç—å—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è\\. –ü—Ä–æ—Ü–µ—Å –æ—á—ñ–∫—É—î\\. –û–±–µ—Ä—ñ—Ç—å –¥—ñ—é:",
                        buttons=[
                            {"text": "–ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏", "callback_data": "skip_image_action"},
                            {"text": "–°–ø—Ä–æ–±—É–≤–∞—Ç–∏ —ñ–Ω—à–∏–º", "callback_data": "regenerate_alt_action"},
                            {"text": "–ü–µ—Ä–µ–º–∫–Ω—É—Ç–∏ –Ω–∞–∑–∞–≤–∂–¥–∏", "callback_data": "switch_service_action"}
                        ]
                    )
                    # –ß–µ–∫–∞—î–º–æ –Ω–∞ –¥—ñ—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
                    while not (self.app.skip_image_event.is_set() or self.app.regenerate_alt_service_event.is_set()):
                        if not self.app._check_app_state(): # –î–æ–∑–≤–æ–ª—è—î –ø–∞—É–∑—É/–ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –ø—ñ–¥ —á–∞—Å –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è
                            all_successful = False
                            break
                        time.sleep(0.5)
                    
                    self.app._update_button_states(is_processing=True, is_image_stuck=False) # –î–µ–∞–∫—Ç–∏–≤—É—î–º–æ –∫–Ω–æ–ø–∫–∏ –ø—ñ—Å–ª—è –¥—ñ—ó
                    continue # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ—Å—å –Ω–∞ –ø–æ—á–∞—Ç–æ–∫ —Ü–∏–∫–ª—É, —â–æ–± –æ–±—Ä–æ–±–∏—Ç–∏ –ø–æ–¥—ñ—é
                
                # –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–ª–æ, –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Ö–æ–¥–∏–º–æ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                all_successful = False
                i += 1

        return all_successful

    def _audio_subs_pipeline_master(self, processing_data):
        """–ö–µ—Ä—É—î –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∏–º –∫–æ–Ω–≤–µ—î—Ä–æ–º –ê—É–¥—ñ–æ -> –°—É–±—Ç–∏—Ç—Ä–∏ –¥–ª—è –∫–æ–∂–Ω–æ—ó –º–æ–≤–∏."""
        logger.info("[Audio/Subs Master] Starting pipeline.")
        num_parallel_chunks = self.config.get('parallel_processing', {}).get('num_chunks', 3)

        for task_key, data in sorted(processing_data.items()):
            if not data.get('text_results'): continue
            
            task_idx_str, lang_code = task_key
            status_key = f"{task_idx_str}_{lang_code}"
            lang_steps = data['task']['steps'][lang_code]
            lang_config = self.config["languages"][lang_code]
            tts_service = lang_config.get("tts_service", "elevenlabs")
            text_to_process = data['text_results']['text_to_process']
            output_path = data['text_results']['output_path']
            
            temp_dir = os.path.join(output_path, "temp_chunks")
            os.makedirs(temp_dir, exist_ok=True)
            data['temp_dir'] = temp_dir
            
            final_audio_chunks = []

            audio_step_name = self.app._t('step_name_audio')
            if lang_steps.get('audio'):
                voicemaker_limit = self.config.get("voicemaker", {}).get("char_limit", 9900)
                text_chunks = []
                if tts_service == "voicemaker" and len(text_to_process) > voicemaker_limit:
                    text_chunks = chunk_text_voicemaker(text_to_process, voicemaker_limit)
                elif tts_service == "speechify" and len(text_to_process) > 16000:
                    text_chunks = chunk_text_speechify(text_to_process, 16000, num_parallel_chunks)
                else:
                    text_chunks = chunk_text(text_to_process, num_parallel_chunks)
                
                if not text_chunks:
                    logger.error(f"Text for {lang_code} is empty after chunking. Skipping.")
                    if status_key in self.app.task_completion_status and audio_step_name in self.app.task_completion_status[status_key]['steps']:
                        self.app.task_completion_status[status_key]['steps'][audio_step_name] = "‚ùå"
                    continue

                self.app.update_progress(f"{lang_code.upper()}: –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è {len(text_chunks)} –∞—É–¥—ñ–æ-—à–º–∞—Ç–∫—ñ–≤...")
                initial_audio_chunks = []
                with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
                    future_to_chunk = {}
                    for i, chunk in enumerate(text_chunks):
                        future = executor.submit(self._audio_generation_worker, chunk, os.path.join(temp_dir, f"audio_chunk_{i}.mp3"), lang_config, lang_code, i + 1, len(text_chunks))
                        future_to_chunk[future] = i
                        time.sleep(1)
                    
                    results = [None] * len(text_chunks)
                    for future in concurrent.futures.as_completed(future_to_chunk):
                        results[future_to_chunk[future]] = future.result()
                initial_audio_chunks = [r for r in results if r]

                if len(initial_audio_chunks) != len(text_chunks):
                     logger.error(f"Failed to generate all audio chunks for {lang_code}. Skipping subs/video.")
                     if status_key in self.app.task_completion_status and audio_step_name in self.app.task_completion_status[status_key]['steps']:
                        self.app.task_completion_status[status_key]['steps'][audio_step_name] = "‚ùå"
                     continue

                if (tts_service in ["voicemaker", "speechify"]) and len(initial_audio_chunks) > num_parallel_chunks:
                    logger.info(f"Merging {len(initial_audio_chunks)} {tts_service} audio chunks into {num_parallel_chunks} final chunks.")
                    chunk_groups = np.array_split(initial_audio_chunks, num_parallel_chunks)
                    
                    for i, group in enumerate(chunk_groups):
                        if not group.any(): continue
                        merged_output_file = os.path.join(temp_dir, f"merged_chunk_{lang_code}_{i}.mp3")
                        if concatenate_audio_files(list(group), merged_output_file):
                            final_audio_chunks.append(merged_output_file)
                        else:
                             logger.error(f"Failed to merge a group of {tts_service} audio files for {lang_code}.")
                else:
                    final_audio_chunks = initial_audio_chunks
                
                if final_audio_chunks:
                     if status_key in self.app.task_completion_status and audio_step_name in self.app.task_completion_status[status_key]['steps']:
                        self.app.task_completion_status[status_key]['steps'][audio_step_name] = "‚úÖ"
                else:
                    logger.error(f"Audio processing resulted in zero final chunks for {lang_code}.")
                    if status_key in self.app.task_completion_status and audio_step_name in self.app.task_completion_status[status_key]['steps']:
                        self.app.task_completion_status[status_key]['steps'][audio_step_name] = "‚ùå"
            else:
                logger.info(f"Audio step disabled for {lang_code}. Searching for existing merged audio chunks...")
                found_chunks = sorted([os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.startswith(f'merged_chunk_{lang_code}_') and f.endswith('.mp3')])
                if found_chunks:
                    logger.info(f"Found {len(found_chunks)} existing merged audio chunks.")
                    final_audio_chunks = found_chunks
                else:
                    logger.warning(f"No merged audio chunks found for {lang_code}. Dependent steps will be skipped.")
            
            if not final_audio_chunks:
                continue

            data['audio_chunks'] = sorted(final_audio_chunks)
            subs_chunk_dir = os.path.join(temp_dir, "subs"); os.makedirs(subs_chunk_dir, exist_ok=True)
            subs_chunk_paths = []
            
            subs_step_name = self.app._t('step_name_create_subtitles')
            if lang_steps.get('create_subtitles'):
                self.app.update_progress(f"{lang_code.upper()}: –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Å—É–±—Ç–∏—Ç—Ä—ñ–≤...")
                subs_chunk_paths = self._sequential_subtitle_worker(data['audio_chunks'], subs_chunk_dir)
                
                if len(subs_chunk_paths) == len(data['audio_chunks']):
                    if status_key in self.app.task_completion_status and subs_step_name in self.app.task_completion_status[status_key]['steps']:
                        self.app.task_completion_status[status_key]['steps'][subs_step_name] = "‚úÖ"
                else:
                    logger.error(f"Failed to generate all subtitle chunks for {lang_code}.")
                    if status_key in self.app.task_completion_status and subs_step_name in self.app.task_completion_status[status_key]['steps']:
                        self.app.task_completion_status[status_key]['steps'][subs_step_name] = "‚ùå"
                    continue
            else:
                logger.info(f"Subtitles step disabled for {lang_code}. Searching for existing subtitle chunks...")
                found_subs = sorted([os.path.join(subs_chunk_dir, f) for f in os.listdir(subs_chunk_dir) if f.startswith('subs_chunk_') and f.endswith('.ass')])
                if len(found_subs) == len(data['audio_chunks']):
                     logger.info(f"Found {len(found_subs)} existing subtitle chunks.")
                     subs_chunk_paths = found_subs
                else:
                    logger.warning(f"Found {len(found_subs)} subtitle chunks, but expected {len(data['audio_chunks'])}. Video montage might fail.")
                    subs_chunk_paths = found_subs 

            data['subs_chunks'] = sorted(subs_chunk_paths)

        logger.info("[Audio/Subs Master] Pipeline finished.")

    def _audio_generation_worker(self, text_chunk, output_path, lang_config, lang_code, chunk_index, total_chunks):
        if hasattr(self.app, 'log_context'):
            self.app.log_context.parallel_task = 'Audio Gen'
            self.app.log_context.worker_id = f'Chunk {chunk_index}/{total_chunks}'
        try:
            tts_service = lang_config.get("tts_service", "elevenlabs")
            logger.info(f"Starting audio generation task with {tts_service}")
            
            if tts_service == "elevenlabs":
                task_id = self.el_api.create_audio_task(text_chunk, lang_config.get("elevenlabs_template_uuid"))
                new_balance = self.el_api.balance
                if new_balance is not None:
                    self.app._update_elevenlabs_balance_labels(new_balance)
                if task_id and task_id != "INSUFFICIENT_BALANCE":
                    if self.el_api.wait_for_elevenlabs_task(self.app, task_id, output_path):
                        return output_path
            
            elif tts_service == "voicemaker":
                voice_id = lang_config.get("voicemaker_voice_id")
                engine = lang_config.get("voicemaker_engine")
                success, new_balance = self.vm_api.generate_audio(text_chunk, voice_id, engine, lang_code, output_path)
                if success:
                    if new_balance is not None:
                        vm_text = new_balance if new_balance is not None else 'N/A'
                        self.app.root.after(0, lambda: self.app.settings_vm_balance_label.config(text=f"{self.app._t('balance_label')}: {vm_text}"))
                        self.app.root.after(0, lambda: self.app.chain_vm_balance_label.config(text=f"{self.app._t('voicemaker_balance_label')}: {vm_text}"))
                        self.app.root.after(0, lambda: self.app.rewrite_vm_balance_label.config(text=f"{self.app._t('voicemaker_balance_label')}: {vm_text}"))
                    return output_path
            
            elif tts_service == "speechify":
                logger.info("[Chain] Using Speechify for TTS.")
                success, _ = self.speechify_api.generate_audio_streaming(
                    text=text_chunk,
                    voice_id=lang_config.get("speechify_voice_id"),
                    model=lang_config.get("speechify_model"),
                    output_path=output_path,
                    emotion=lang_config.get("speechify_emotion"),
                    pitch=lang_config.get("speechify_pitch", 0),
                    rate=lang_config.get("speechify_rate", 0)
                )
                if success:
                    return output_path

            logger.error(f"Failed to generate audio chunk using {tts_service}")
            return None
        finally:
            if hasattr(self.app, 'log_context'):
                if hasattr(self.app.log_context, 'parallel_task'): del self.app.log_context.parallel_task
                if hasattr(self.app.log_context, 'worker_id'): del self.app.log_context.worker_id

    def _sequential_subtitle_worker(self, audio_chunk_paths: list, subs_chunk_dir: str) -> list:
        logger.info(f"Starting sequential subtitle generation for {len(audio_chunk_paths)} audio chunks.")
        subs_chunk_paths = []
        total_chunks = len(audio_chunk_paths)
        for i, audio_path in enumerate(audio_chunk_paths):
            self.app.update_progress(self.app._t('transcribing_chunk', current=i + 1, total=total_chunks))
            subs_path = os.path.join(subs_chunk_dir, f"subs_chunk_{i}.ass")
            if self.montage_api.create_subtitles(audio_path, subs_path):
                subs_chunk_paths.append(subs_path)
            else:
                logger.error(f"Failed to generate subtitle chunk for {audio_path}.")
        
        logger.info(f"Finished subtitle generation. Successfully created {len(subs_chunk_paths)} subtitle files.")
        return sorted(subs_chunk_paths)

    def _concatenate_videos(self, app_instance, video_chunks, output_path):
        """–û–±'—î–¥–Ω–∞–Ω–Ω—è –≤—ñ–¥–µ–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ñ–≤."""
        return concatenate_videos(app_instance, video_chunks, output_path)

    def _video_chunk_worker(self, app_instance, image_chunk, audio_path, subs_path, output_path, chunk_num, total_chunks):
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –æ–¥–Ω–æ–≥–æ –≤—ñ–¥–µ–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç—É."""
        from utils.media_utils import video_chunk_worker
        return video_chunk_worker(app_instance, image_chunk, audio_path, subs_path, output_path, chunk_num, total_chunks)

    def _audio_worker(self, data):
        """–ì–µ–Ω–µ—Ä—É—î –¢–Ü–õ–¨–ö–ò –∞—É–¥—ñ–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ –º–æ–≤–Ω–æ–≥–æ –∑–∞–≤–¥–∞–Ω–Ω—è (–¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫—É)."""
        try:
            task = data['task']
            lang_code = data['text_results']['output_path'].split(os.sep)[-1].lower()
            lang_steps = task['steps'][lang_code]
            output_path = data['text_results']['output_path']
            text_to_process = data['text_results']['text_to_process']
            lang_config = self.app.config["languages"][lang_code]
            
            audio_path = os.path.join(output_path, "audio.mp3")

            if lang_steps.get('audio'):
                logger.info(f"[AudioWorker] Starting parallel audio generation for {lang_code}...")
                tts_service = lang_config.get("tts_service", "elevenlabs")
                if tts_service == "elevenlabs":
                    task_id = self.app.el_api.create_audio_task(text_to_process, lang_config.get("elevenlabs_template_uuid"))
                    if task_id and self.app.el_api.wait_for_elevenlabs_task(self.app, task_id, audio_path):
                        logger.info(f"[AudioWorker] ElevenLabs audio saved for {lang_code}.")
                        return audio_path
                elif tts_service == "voicemaker":
                    success, _ = self.app.vm_api.generate_audio(text_to_process, lang_config.get("voicemaker_voice_id"), lang_config.get("voicemaker_engine"), lang_code, audio_path)
                    if success:
                        return audio_path
            
            return None # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ None, —è–∫—â–æ –∞—É–¥—ñ–æ –Ω–µ —Å—Ç–≤–æ—Ä—é–≤–∞–ª–æ—Å—è –∞–±–æ —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞
        except Exception as e:
            logger.exception(f"Error in parallel audio worker: {e}")
            return None
        
    def _parallel_audio_master(self, processing_data):
        """–ì–æ–ª–æ–≤–Ω–∏–π –ø–æ—Ç—ñ–∫, —â–æ –∫–µ—Ä—É—î –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—é –≥–µ–Ω–µ—Ä–∞—Ü—ñ—î—é –≤—Å—ñ—Ö –∞—É–¥—ñ–æ—Ñ–∞–π–ª—ñ–≤."""
        logger.info("[Image Control] Audio Master Thread: Starting parallel audio generation.")
        with concurrent.futures.ThreadPoolExecutor() as executor:
            audio_futures = {}
            for task_key, data in processing_data.items():
                if data.get('text_results') and data['task']['steps'][task_key[1]].get('audio'):
                    future = executor.submit(self._audio_worker, data)
                    audio_futures[future] = task_key
            
            for future in concurrent.futures.as_completed(audio_futures):
                task_key = audio_futures[future]
                # –†–µ–∑—É–ª—å—Ç–∞—Ç (—à–ª—è—Ö –¥–æ –∞—É–¥—ñ–æ) –∑–∞–ø–∏—Å—É—î—Ç—å—Å—è –≤ –∑–∞–≥–∞–ª—å–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫
                processing_data[task_key]['audio_path'] = future.result()
        logger.info("[Image Control] Audio Master Thread: All audio generation tasks complete.")
